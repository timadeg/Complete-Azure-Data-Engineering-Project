# End-to-End Azure NHS Prescription Data Project

This project demonstrates an end-to-end data engineering pipeline on Azure, focusing on the analysis of **NHS English Prescribing Data (EPD)** from 2020 to 2024. The goal was to extract, transform, and load (ETL) monthly prescribing datasets from the NHS open data API into Azure Data Lake, process and clean the data in Synapse Spark, and build insightful analytics in Power BI.

---

## üß† Business Objective

To understand prescribing trends, drug usage patterns, and regional cost distribution of NHS medicines across England using real public health data. The project provides a reproducible framework for handling large-scale healthcare data using modern Azure tools.

---

## üíæ Data Sources

- NHSBSA Open Data Portal:  
  `https://opendata.nhsbsa.net/`  
- Dataset: **English Prescribing Data (EPD)**  
- Time Range: **2020‚Äì2024**

---

## üöÄ Tech Stack

<img width="983" height="327" alt="image" src="https://github.com/user-attachments/assets/c6a381c9-5f72-479b-bf60-3021b5d52900" />

| Tool | Purpose |
|------|---------|
| Azure Data Factory | Automated REST API ingestion to ADLS |
| Azure Data Lake Storage Gen2 | Centralized cloud data storage |
| Azure Synapse Analytics | Data cleaning & transformation using Spark notebooks |
| Power BI | Data visualization and interactive dashboard |

---

## 1Ô∏è‚É£ Data Ingestion

Using **Azure Data Factory**, we performed the following:

- Parameterized REST API calls to fetch monthly prescribing datasets via SQL queries
- Looped through resource IDs for all months between 2020‚Äì2024
- Saved each dataset as a `.csv` file into ADLS "raw" zone

> Sample API structure used:  
> `https://opendata.nhsbsa.net/api/3/action/datastore_search_sql?resource_id=EPD_202401&sql=SELECT * FROM "EPD_202401" WHERE pco_code='13T00' AND bnf_chemical_substance='0407010H0'`

---

## 2Ô∏è‚É£ Data Cleaning (Synapse Spark)

<img width="1334" height="690" alt="Screenshot 2025-07-15 105436" src="https://github.com/user-attachments/assets/b47b7a5c-6604-459a-bfc2-1e293d63983a" />

After ingestion, the data was cleaned in **Synapse Spark Notebooks**:

- Raw CSVs contained all data in a single column
- Used PySpark to split columns, remove nulls, and cast data types
- Extracted `Year` and `Month` from the `YEAR_MONTH` column
- Created derived columns such as `Cost per Item` and `Cost per Quantity`

Final cleaned data was saved into a **clean zone** in ADLS as Parquet files.

---

## 3Ô∏è‚É£ Data Modeling & Analytics (Power BI)

<img width="992" height="568" alt="image" src="https://github.com/user-attachments/assets/de15a8b6-5727-4b5c-a092-ba18e84fd283" />


The clean data was connected to Power BI via **Azure Data Lake**.

### üìä Key KPIs:

- Total Items Prescribed
- Total Net Ingredient Cost (NIC)
- Total Actual Cost
- Cost per Item
- Most Prescribed Chemicals
- Cost by Region, Practice, ICB

### üìà Visualizations:

- Line charts for prescribing trends over time
- Bar charts for Top 10 BNF Substances by cost
- Tree map of costs by ICB and Regional Office
- Slicers for Year, Month, Practice, Chemical
- Map of prescribing cost by location

---

## üß™ Final Dashboard Highlights

- Prescribing patterns from 2020 to 2024
- Dynamic insights by region, chemical, or time
- Easily extensible pipeline for future months or filters

---

## üß© Challenges & Notes

<img width="1332" height="533" alt="image" src="https://github.com/user-attachments/assets/bcdb06ae-3266-4cea-9d41-ac17be9ec977" />

- NHS API returned raw data in one-column CSVs ‚Äî required parsing in Spark
- Some columns had inconsistent types (e.g., cost as string)
- Data volume was large but manageable in Spark with optimized file formats (Parquet)

---

## ‚úÖ Conclusion

This project shows how to build a **real-world, scalable healthcare data pipeline on Azure**, using modern data engineering techniques:

- Automated ingestion via REST API
- Spark-based cleaning in Synapse
- Interactive BI via Power BI and ADLS

